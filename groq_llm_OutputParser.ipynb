{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00655e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c5eb2",
   "metadata": {},
   "source": [
    "### CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab6e4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['subject'], input_types={}, partial_variables={'format_instructions': 'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'}, template='List five {subject}.\\n{format_instructions}')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import csv\n",
    "\n",
    "# ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ ê°€ì ¸ì˜¤ê¸°\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2ec6a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI ê´€ë ¨ ê¸°ìˆ  ëª©ë¡:\n",
      "['Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Computer Vision', 'Robotics']\n",
      " './data/ai_technologies.csv' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# OpenAI ëª¨ë¸ ì„¤ì •\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ì—¬ ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# \"AI ê´€ë ¨ ê¸°ìˆ \"ì— ëŒ€í•œ ì²´ì¸ í˜¸ì¶œ ì‹¤í–‰\n",
    "result = chain.invoke({\"subject\": \"AI ê´€ë ¨ ê¸°ìˆ \"})\n",
    "\n",
    "# ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\n",
    "print(\" AI ê´€ë ¨ ê¸°ìˆ  ëª©ë¡:\")\n",
    "print(result)\n",
    "\n",
    "# ê²°ê³¼ í™œìš© ì˜ˆì‹œ: CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "csv_filename = \"./data/ai_technologies.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"AI ê¸°ìˆ \"])  # í—¤ë” ì¶”ê°€\n",
    "    for item in result:\n",
    "        writer.writerow([item])\n",
    "\n",
    "print(f\" '{csv_filename}' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb522984",
   "metadata": {},
   "source": [
    "### JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a92e6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={'format_instructions': 'Return a JSON object.'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê³¼í•™ ë¶„ì•¼ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ì²´ê³„ì ì´ê³  ê°„ê²°í•œ ë‹µë³€ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'question'], input_types={}, partial_variables={}, template='#Format: {format_instructions}\\n\\n#Question: {question}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "# JSON ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ê³¼í•™ ë¶„ì•¼ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ì²´ê³„ì ì´ê³  ê°„ê²°í•œ ë‹µë³€ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.\"),\n",
    "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# JSON ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ì„ í”„ë¡¬í”„íŠ¸ì— ì ìš©\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "527e902b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"mission_name\": \"ë‰´í˜¸ë¼ì´ì¦ŒìŠ¤\",\n",
      "        \"goal\": \"ëª…ì™•ì„± íƒì‚¬\",\n",
      "        \"agency\": \"NASA\"\n",
      "    },\n",
      "    {\n",
      "        \"mission_name\": \"ì¹´ì‹œë‹ˆ-í˜¸ì´ê²ìŠ¤\",\n",
      "        \"goal\": \"í† ì„±ì˜ ìœ„ì„± íƒ€ì´íƒ„ íƒì‚¬\",\n",
      "        \"agency\": \"NASA, ESA, ì´íƒˆë¦¬ì•„ ìš°ì£¼êµ­\"\n",
      "    },\n",
      "    {\n",
      "        \"mission_name\": \"ì°½ì–´ 4í˜¸\",\n",
      "        \"goal\": \"ë‹¬ì˜ ë’·ë©´ íƒì‚¬\",\n",
      "        \"agency\": \"ì¤‘êµ­ ìš°ì£¼êµ­\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# OpenAI ëª¨ë¸ ì„¤ì •\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "# í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ëŠ” ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì§ˆë¬¸ ì„¤ì • (ìš°ì£¼ íƒì‚¬ ê´€ë ¨ ì§ˆë¬¸)\n",
    "question = \"ìµœê·¼ 10ë…„ê°„ ì§„í–‰ëœ ì£¼ìš” ìš°ì£¼ íƒì‚¬ ë¯¸ì…˜ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. \\\n",
    "ê° ë¯¸ì…˜ì˜ ì´ë¦„ì€ `mission_name`ì—, ëª©í‘œëŠ” `goal`ì—, ì£¼ê´€ ê¸°ê´€ì€ `agency`ì— ë‹´ì•„ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ ë° JSON ì‘ë‹µ ë°›ê¸°\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "# JSON ë°ì´í„° ì¶œë ¥\n",
    "print(json.dumps(response, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f8b67c",
   "metadata": {},
   "source": [
    "### PandasDataFrameOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "578f4bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a string as the operation, followed by a colon, followed by the column or row to be queried on, followed by optional array parameters.\n",
      "1. The column names are limited to the possible columns below.\n",
      "2. Arrays must either be a comma-separated list of numbers formatted as [1,3,5], or it must be in range of numbers formatted as [0..4].\n",
      "3. Remember that arrays are optional and not necessarily required.\n",
      "4. If the column is not in the possible columns or the operation is not a valid Pandas DataFrame operation, return why it is invalid as a sentence starting with either \"Invalid column\" or \"Invalid operation\".\n",
      "\n",
      "As an example, for the formats:\n",
      "1. String \"column:num_legs\" is a well-formatted instance which gets the column num_legs, where num_legs is a possible column.\n",
      "2. String \"row:1\" is a well-formatted instance which gets row 1.\n",
      "3. String \"column:num_legs[1,2]\" is a well-formatted instance which gets the column num_legs for rows 1 and 2, where num_legs is a possible column.\n",
      "4. String \"row:1[num_legs]\" is a well-formatted instance which gets row 1, but for just column num_legs, where num_legs is a possible column.\n",
      "5. String \"mean:num_legs[1..3]\" is a well-formatted instance which takes the mean of num_legs from rows 1 to 3, where num_legs is a possible column and mean is a valid Pandas DataFrame operation.\n",
      "6. String \"do_something:num_legs\" is a badly-formatted instance, where do_something is not a valid Pandas DataFrame operation.\n",
      "7. String \"mean:invalid_col\" is a badly-formatted instance, where invalid_col is not a possible column.\n",
      "\n",
      "Here are the possible columns:\n",
      "```\n",
      "Survived, Pclass, Name, Sex, Age, Siblings/Spouses Aboard, Parents/Children Aboard, Fare\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from typing import Any, Dict\n",
    "import pandas as pd\n",
    "from langchain.output_parsers import PandasDataFrameOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ì›¹ì—ì„œ Titanic ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv('./data/titanic.csv')\n",
    "\n",
    "# Pandas DataFrame Output Parser ì„¤ì •\n",
    "parser = PandasDataFrameOutputParser(dataframe=df)\n",
    "\n",
    "# í˜•ì‹ ì§€ì¹¨ ì¶œë ¥\n",
    "format_instructions = parser.get_format_instructions()\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8fd7c",
   "metadata": {},
   "source": [
    "gptì—ì„œ ì‹¤í–‰í•˜ë©´ ë˜ì§€ë§Œ ë¼ë§ˆ ì‹¤í–‰ì‹œ ì˜¤ë¥˜ê°€ ëœ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f339982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived, Pclass, Name, Sex, Age, Siblings/Spouses Aboard, Parents/Children Aboard, Fare\n"
     ]
    }
   ],
   "source": [
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "# model = ChatOpenAI(\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    You are a helpful assistant that interacts with a Pandas DataFrame.\n",
    "    The DataFrame contains the following columns: {columns}.\n",
    "    \n",
    "    Your task is to answer the user's query by generating a command in the following format:\n",
    "    {format_instructions}\n",
    "    \n",
    "    User Query: {query}    \n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": format_instructions,\n",
    "        \"columns\": \", \".join(df.columns)\n",
    "    },\n",
    ")\n",
    "print(prompt.partial_variables['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbadc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ëª¨ë¸ ì‘ë‹µ ë°›ê¸°\n",
    "try:\n",
    "    # **Name ì—´ì„ í‘œì‹œí•˜ì‹­ì‹œì˜¤.**\n",
    "    print('Name ì»¬ëŸ¼ ì¶œë ¥')\n",
    "    df_query = \"Show the Name column\"\n",
    "\n",
    "    parser_output = chain.invoke({\"query\": df_query})\n",
    "    print(type(parser_output))\n",
    "    print(parser_output)\n",
    "\n",
    "    # **ì²«ë²ˆì§¸ í–‰ì„ í‘œì‹œí•˜ì‹­ì‹œì˜¤.**\n",
    "    print('ì²«ë²ˆì§¸ í–‰ ì¶œë ¥')\n",
    "    df_query2 = \"Show first row\"\n",
    "\n",
    "    parser_output2 = chain.invoke({\"query\": df_query2})\n",
    "    print(parser_output2)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b07a05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] input_types={} partial_variables={'format_instructions': 'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"data\": string  // A list of dictionaries representing table rows.\\n}\\n```'} template='\\n    You are an AI assistant that generates tabular data. \\n    You must return the data in JSON format that follows this schema:\\n\\n    {format_instructions}\\n\\n    **User Query:**\\n    {query}\\n    '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "# model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ì •ì˜ {data : [{},{},{}] }\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"data\", description=\"A list of dictionaries representing table rows.\"),\n",
    "]\n",
    "\n",
    "# Output Parser ì„¤ì •\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an AI assistant that generates tabular data. \n",
    "    You must return the data in JSON format that follows this schema:\n",
    "    \n",
    "    {format_instructions}\n",
    "        \n",
    "    **User Query:**\n",
    "    {query}\n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0bd88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ ìƒì„± (í”„ë¡¬í”„íŠ¸ â†’ ëª¨ë¸ â†’ OutputParser)\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì‹¤í–‰ í•¨ìˆ˜\n",
    "def generate_dataframe(user_query):\n",
    "    try:\n",
    "        # ëª¨ë¸ í˜¸ì¶œ\n",
    "        json_response = chain.invoke({\"query\": user_query})\n",
    "        print(json_response)\n",
    "        \n",
    "        # ëª¨ë¸ì´ ë°˜í™˜í•œ JSONì„ Pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "        df = pd.DataFrame(json_response[\"data\"])\n",
    "\n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        print(\"\\nğŸ”¹ Generated DataFrame:\\n\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a27ff9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024ë…„ í•˜ë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±\n",
      "{'data': [{'District': 'Gangnam-gu', 'Average Price (KRW)': 1200000000, 'Number of Transactions': 150, 'Year-over-Year Change (%)': 10.2}, {'District': 'Gangdong-gu', 'Average Price (KRW)': 900000000, 'Number of Transactions': 120, 'Year-over-Year Change (%)': 8.5}, {'District': 'Gwangjin-gu', 'Average Price (KRW)': 1000000000, 'Number of Transactions': 180, 'Year-over-Year Change (%)': 12.1}, {'District': 'Dongdaemun-gu', 'Average Price (KRW)': 800000000, 'Number of Transactions': 100, 'Year-over-Year Change (%)': 6.8}, {'District': 'Dongjak-gu', 'Average Price (KRW)': 950000000, 'Number of Transactions': 140, 'Year-over-Year Change (%)': 9.2}, {'District': 'Eunpyeong-gu', 'Average Price (KRW)': 700000000, 'Number of Transactions': 80, 'Year-over-Year Change (%)': 5.5}, {'District': 'Geumcheon-gu', 'Average Price (KRW)': 600000000, 'Number of Transactions': 60, 'Year-over-Year Change (%)': 4.2}, {'District': 'Gu-ro-gu', 'Average Price (KRW)': 850000000, 'Number of Transactions': 110, 'Year-over-Year Change (%)': 7.5}, {'District': 'Gwanak-gu', 'Average Price (KRW)': 650000000, 'Number of Transactions': 90, 'Year-over-Year Change (%)': 5.8}, {'District': 'Gwangju', 'Average Price (KRW)': 750000000, 'Number of Transactions': 130, 'Year-over-Year Change (%)': 8.1}, {'District': 'Jongno-gu', 'Average Price (KRW)': 1400000000, 'Number of Transactions': 160, 'Year-over-Year Change (%)': 11.5}, {'District': 'Mapo-gu', 'Average Price (KRW)': 1100000000, 'Number of Transactions': 170, 'Year-over-Year Change (%)': 10.8}, {'District': 'Nowon-gu', 'Average Price (KRW)': 720000000, 'Number of Transactions': 85, 'Year-over-Year Change (%)': 6.2}, {'District': 'Oeuljeon-gu', 'Average Price (KRW)': 820000000, 'Number of Transactions': 105, 'Year-over-Year Change (%)': 7.1}, {'District': 'Seodaemun-gu', 'Average Price (KRW)': 900000000, 'Number of Transactions': 125, 'Year-over-Year Change (%)': 8.8}, {'District': 'Seongbuk-gu', 'Average Price (KRW)': 950000000, 'Number of Transactions': 145, 'Year-over-Year Change (%)': 9.5}, {'District': 'Songpa-gu', 'Average Price (KRW)': 1300000000, 'Number of Transactions': 190, 'Year-over-Year Change (%)': 11.8}, {'District': 'Yangcheon-gu', 'Average Price (KRW)': 780000000, 'Number of Transactions': 95, 'Year-over-Year Change (%)': 6.5}, {'District': 'Yangpyeong-gu', 'Average Price (KRW)': 680000000, 'Number of Transactions': 75, 'Year-over-Year Change (%)': 5.1}, {'District': 'Yongsan-gu', 'Average Price (KRW)': 1500000000, 'Number of Transactions': 200, 'Year-over-Year Change (%)': 12.5}, {'District': 'Yonsei-ro', 'Average Price (KRW)': 1600000000, 'Number of Transactions': 220, 'Year-over-Year Change (%)': 13.2}]}\n",
      "\n",
      "ğŸ”¹ Generated DataFrame:\n",
      "\n",
      "(21, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "      <th>Average Price (KRW)</th>\n",
       "      <th>Number of Transactions</th>\n",
       "      <th>Year-over-Year Change (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gangnam-gu</td>\n",
       "      <td>1200000000</td>\n",
       "      <td>150</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gangdong-gu</td>\n",
       "      <td>900000000</td>\n",
       "      <td>120</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gwangjin-gu</td>\n",
       "      <td>1000000000</td>\n",
       "      <td>180</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dongdaemun-gu</td>\n",
       "      <td>800000000</td>\n",
       "      <td>100</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dongjak-gu</td>\n",
       "      <td>950000000</td>\n",
       "      <td>140</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eunpyeong-gu</td>\n",
       "      <td>700000000</td>\n",
       "      <td>80</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Geumcheon-gu</td>\n",
       "      <td>600000000</td>\n",
       "      <td>60</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gu-ro-gu</td>\n",
       "      <td>850000000</td>\n",
       "      <td>110</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gwanak-gu</td>\n",
       "      <td>650000000</td>\n",
       "      <td>90</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gwangju</td>\n",
       "      <td>750000000</td>\n",
       "      <td>130</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jongno-gu</td>\n",
       "      <td>1400000000</td>\n",
       "      <td>160</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mapo-gu</td>\n",
       "      <td>1100000000</td>\n",
       "      <td>170</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nowon-gu</td>\n",
       "      <td>720000000</td>\n",
       "      <td>85</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Oeuljeon-gu</td>\n",
       "      <td>820000000</td>\n",
       "      <td>105</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Seodaemun-gu</td>\n",
       "      <td>900000000</td>\n",
       "      <td>125</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Seongbuk-gu</td>\n",
       "      <td>950000000</td>\n",
       "      <td>145</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Songpa-gu</td>\n",
       "      <td>1300000000</td>\n",
       "      <td>190</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Yangcheon-gu</td>\n",
       "      <td>780000000</td>\n",
       "      <td>95</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Yangpyeong-gu</td>\n",
       "      <td>680000000</td>\n",
       "      <td>75</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Yongsan-gu</td>\n",
       "      <td>1500000000</td>\n",
       "      <td>200</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Yonsei-ro</td>\n",
       "      <td>1600000000</td>\n",
       "      <td>220</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         District  Average Price (KRW)  Number of Transactions  \\\n",
       "0      Gangnam-gu           1200000000                     150   \n",
       "1     Gangdong-gu            900000000                     120   \n",
       "2     Gwangjin-gu           1000000000                     180   \n",
       "3   Dongdaemun-gu            800000000                     100   \n",
       "4      Dongjak-gu            950000000                     140   \n",
       "5    Eunpyeong-gu            700000000                      80   \n",
       "6    Geumcheon-gu            600000000                      60   \n",
       "7        Gu-ro-gu            850000000                     110   \n",
       "8       Gwanak-gu            650000000                      90   \n",
       "9         Gwangju            750000000                     130   \n",
       "10      Jongno-gu           1400000000                     160   \n",
       "11        Mapo-gu           1100000000                     170   \n",
       "12       Nowon-gu            720000000                      85   \n",
       "13    Oeuljeon-gu            820000000                     105   \n",
       "14   Seodaemun-gu            900000000                     125   \n",
       "15    Seongbuk-gu            950000000                     145   \n",
       "16      Songpa-gu           1300000000                     190   \n",
       "17   Yangcheon-gu            780000000                      95   \n",
       "18  Yangpyeong-gu            680000000                      75   \n",
       "19     Yongsan-gu           1500000000                     200   \n",
       "20      Yonsei-ro           1600000000                     220   \n",
       "\n",
       "    Year-over-Year Change (%)  \n",
       "0                        10.2  \n",
       "1                         8.5  \n",
       "2                        12.1  \n",
       "3                         6.8  \n",
       "4                         9.2  \n",
       "5                         5.5  \n",
       "6                         4.2  \n",
       "7                         7.5  \n",
       "8                         5.8  \n",
       "9                         8.1  \n",
       "10                       11.5  \n",
       "11                       10.8  \n",
       "12                        6.2  \n",
       "13                        7.1  \n",
       "14                        8.8  \n",
       "15                        9.5  \n",
       "16                       11.8  \n",
       "17                        6.5  \n",
       "18                        5.1  \n",
       "19                       12.5  \n",
       "20                       13.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [ì˜ˆì œ 1] 2024ë…„ ìƒë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±\n",
    "print('2024ë…„ í•˜ë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±')\n",
    "df_seoul_housing = generate_dataframe(\n",
    "    \"Create a dataset of the average apartment sale prices in Seoul for the second half of 2024 with columns: District (êµ¬), Average Price (in KRW), Number of Transactions, and Year-over-Year Change (%).\"\n",
    ")\n",
    "print(df_seoul_housing.shape)\n",
    "df_seoul_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e357ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°\n",
      "{'data': [{'Station Name': 'Gangnam Station', 'Line Number': '2', 'Daily Passenger Volume': '146,321', 'Weekday vs Weekend Ratio': '1.23'}, {'Station Name': 'Hongdae Station', 'Line Number': '2', 'Daily Passenger Volume': '134,819', 'Weekday vs Weekend Ratio': '1.17'}, {'Station Name': 'Itaewon Station', 'Line Number': '4', 'Daily Passenger Volume': '123,456', 'Weekday vs Weekend Ratio': '1.05'}, {'Station Name': 'Yongsan Station', 'Line Number': '1, 4', 'Daily Passenger Volume': '114,285', 'Weekday vs Weekend Ratio': '1.22'}, {'Station Name': 'Jamsil Station', 'Line Number': '2, 8', 'Daily Passenger Volume': '107,692', 'Weekday vs Weekend Ratio': '1.11'}, {'Station Name': 'Bongeunsa Station', 'Line Number': '2', 'Daily Passenger Volume': '104,167', 'Weekday vs Weekend Ratio': '1.19'}, {'Station Name': 'Seoul Station', 'Line Number': '1, 4, Gyeongbu', 'Daily Passenger Volume': '98,654', 'Weekday vs Weekend Ratio': '1.25'}, {'Station Name': 'Dongdaemun History & Culture Park Station', 'Line Number': '2, 4, 5', 'Daily Passenger Volume': '94,286', 'Weekday vs Weekend Ratio': '1.08'}, {'Station Name': 'Myeong-dong Station', 'Line Number': '4', 'Daily Passenger Volume': '92,381', 'Weekday vs Weekend Ratio': '1.16'}, {'Station Name': 'Insadong Station', 'Line Number': '3', 'Daily Passenger Volume': '88,462', 'Weekday vs Weekend Ratio': '1.04'}]}\n",
      "\n",
      "ğŸ”¹ Generated DataFrame:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°')\n",
    "# [ì˜ˆì œ 2] 2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°\n",
    "df_seoul_subway = generate_dataframe(\n",
    "    \"Generate a dataset of the top 10 busiest subway stations in Seoul in 2024 with columns: Station Name, Line Number, Daily Passenger Volume, and Weekday vs Weekend Ratio.\"\n",
    ")\n",
    "if df_seoul_subway is not None:\n",
    "    #print(df_seoul_subway.shape)\n",
    "    df_seoul_subway.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e436099b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜\n",
      "{'data': [{'Brand Name': 'CU', 'Number of Stores': 15432, 'Total Revenue': 11.5, 'Market Share': 27.3}, {'Brand Name': 'GS25', 'Number of Stores': 13345, 'Total Revenue': 9.8, 'Market Share': 23.5}, {'Brand Name': '7-Eleven', 'Number of Stores': 11256, 'Total Revenue': 8.2, 'Market Share': 20.2}, {'Brand Name': 'E-Mart24', 'Number of Stores': 9012, 'Total Revenue': 6.5, 'Market Share': 16.1}, {'Brand Name': 'Homeplus', 'Number of Stores': 7010, 'Total Revenue': 5.2, 'Market Share': 12.9}]}\n",
      "\n",
      "ğŸ”¹ Generated DataFrame:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Number of Stores</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Market Share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CU</td>\n",
       "      <td>15432</td>\n",
       "      <td>11.5</td>\n",
       "      <td>27.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GS25</td>\n",
       "      <td>13345</td>\n",
       "      <td>9.8</td>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7-Eleven</td>\n",
       "      <td>11256</td>\n",
       "      <td>8.2</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E-Mart24</td>\n",
       "      <td>9012</td>\n",
       "      <td>6.5</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homeplus</td>\n",
       "      <td>7010</td>\n",
       "      <td>5.2</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Brand Name  Number of Stores  Total Revenue  Market Share\n",
       "0         CU             15432           11.5          27.3\n",
       "1       GS25             13345            9.8          23.5\n",
       "2   7-Eleven             11256            8.2          20.2\n",
       "3   E-Mart24              9012            6.5          16.1\n",
       "4   Homeplus              7010            5.2          12.9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜')\n",
    "# [ì˜ˆì œ 3] í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜\n",
    "df_korean_convenience_stores = generate_dataframe(\n",
    "    \"Create a dataset of the top 5 convenience store brands in Korea in 2024 with columns: Brand Name, Number of Stores, Total Revenue (in billion KRW), and Market Share (%).\"\n",
    ")\n",
    "df_korean_convenience_stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364a4fa",
   "metadata": {},
   "source": [
    "### PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abe88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‘˜ ì¤‘ í•˜ë‚˜ê°€ í•„ìš”!\n",
    "# poetry add pydantic\n",
    "# %pip install pydantic\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0735d5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] input_types={} partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"movie_title\": {\"description\": \"ì¶”ì²œ ì˜í™” ì œëª©\", \"title\": \"Movie Title\", \"type\": \"string\"}, \"reason\": {\"description\": \"ì¶”ì²œ ì´ìœ \", \"title\": \"Reason\", \"type\": \"string\"}, \"genre\": {\"description\": \"ì˜í™” ì¥ë¥´\", \"items\": {\"type\": \"string\"}, \"title\": \"Genre\", \"type\": \"array\"}, \"estimated_rating\": {\"description\": \"10ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \", \"title\": \"Estimated Rating\", \"type\": \"number\"}}, \"required\": [\"movie_title\", \"reason\", \"genre\", \"estimated_rating\"]}\\n```'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'query'], input_types={}, partial_variables={}, template='\\në‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì˜í™”ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.\\nìš”ì²­: {query}\\n\\n{format_instructions}\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# ì¶œë ¥ êµ¬ì¡°ë¥¼ ì •ì˜í•˜ëŠ” Pydantic ëª¨ë¸\n",
    "class MovieRecommendation(BaseModel):\n",
    "    movie_title: str = Field(description=\"ì¶”ì²œ ì˜í™” ì œëª©\")\n",
    "    reason: str = Field(description=\"ì¶”ì²œ ì´ìœ \")\n",
    "    genre: List[str] = Field(description=\"ì˜í™” ì¥ë¥´\")\n",
    "    estimated_rating: float = Field(description=\"10ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \")\n",
    "    \n",
    "# Pydantic ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = PydanticOutputParser(pydantic_object=MovieRecommendation)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "template = \"\"\"\n",
    "ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì˜í™”ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n",
    "ìš”ì²­: {query}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# íŒŒì„œì˜ ì§€ì‹œì‚¬í•­ì„ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…\n",
    "prompt = prompt.partial(\n",
    "    format_instructions=parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "249d0782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶”ì²œ ì˜í™”: ì¸ì–´ê³µì£¼\n",
      "ì¶”ì²œ ì´ìœ : ë””ì¦ˆë‹ˆì˜ ëŒ€í‘œì‘ ì¤‘ í•˜ë‚˜ë¡œ, ê°ì„± ë‚­ë‚­í•œ ìŒì•…ê³¼ ì•„ë¦„ë‹¤ìš´ ì• ë‹ˆë©”ì´ì…˜ìœ¼ë¡œ ìœ ëª…í•©ë‹ˆë‹¤.\n",
      "ì¥ë¥´: ì• ë‹ˆë©”ì´ì…˜, ìŒì•…, ë¡œë§¨ìŠ¤\n",
      "ì˜ˆìƒ í‰ì : 8.5/10\n"
     ]
    }
   ],
   "source": [
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "#model = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„± ë° ì‹¤í–‰\n",
    "query = \"ë””ì¦ˆë‹ˆ ì˜í™”ì˜ ì•½ê°„ ê°ì„± ë‚­ë‚­í•œ ëŠë‚Œì„ ë³´ê³  ì‹¶ì€ë° ê°€ì¥ ë””ì¦ˆë‹ˆìŠ¤ëŸ¬ìš´ ì˜í™” ì¶”ì²œ í•´ì¤˜\"\n",
    "chain = prompt | model | parser\n",
    "output = chain.invoke({\"query\": query})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ì¶”ì²œ ì˜í™”: {output.movie_title}\")\n",
    "print(f\"ì¶”ì²œ ì´ìœ : {output.reason}\")\n",
    "print(f\"ì¥ë¥´: {', '.join(output.genre)}\")\n",
    "print(f\"ì˜ˆìƒ í‰ì : {output.estimated_rating}/10\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3377e03",
   "metadata": {},
   "source": [
    "### StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9304721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­:\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"rating\": string  // 5ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \n",
      "\t\"pros\": string  // ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ì¥ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\n",
      "\t\"cons\": string  // ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ë‹¨ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\n",
      "\t\"summary\": string  // ë¦¬ë·°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# ì¶œë ¥ êµ¬ì¡° ì •ì˜ (í‰ì , ì¥ì , ë‹¨ì , ìš”ì•½)\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"rating\", description=\"5ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \"),\n",
    "    ResponseSchema(name=\"pros\", description=\"ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ì¥ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\"),\n",
    "    ResponseSchema(name=\"cons\", description=\"ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ë‹¨ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\"),\n",
    "    ResponseSchema(name=\"summary\", description=\"ë¦¬ë·°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½\")\n",
    "]\n",
    "\n",
    "# íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "print(\"ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­:\")\n",
    "print(format_instructions)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "template = \"\"\"\n",
    "ë‹¤ìŒ ì œí’ˆ ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ì„¸ìš”. ë¦¬ë·° ë‚´ìš©: {review}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4901363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ë¶„ì„ ê²°ê³¼ =====\n",
      "{'cons': ['ê°€ê²©ì´ ì¡°ê¸ˆ ë¹„ì‹¸ë‹¤', 'ë¬´ê²Œê°€ 200gì´ ë„˜ì–´ì„œ ì†ì´ í”¼ê³¤í•  ìˆ˜ ìˆë‹¤'],\n",
      " 'pros': ['ë°°í„°ë¦¬ ìˆ˜ëª…ì´ ì •ë§ ì¢‹ë‹¤', 'ì¹´ë©”ë¼ í™”ì§ˆì´ ì„ ëª…í•˜ë‹¤', 'ì•¼ê°„ ëª¨ë“œê°€ í›Œë¥­í•˜ë‹¤'],\n",
      " 'rating': '4',\n",
      " 'summary': 'ìŠ¤ë§ˆíŠ¸í°ì˜ ë°°í„°ë¦¬ ìˆ˜ëª…ê³¼ ì¹´ë©”ë¼ ì„±ëŠ¥ì€ ìš°ìˆ˜í•˜ë‚˜, ê°€ê²©ê³¼ ë¬´ê²Œê°€ ë‹¤ì†Œ ë¶€ë‹´ìŠ¤ëŸ½ë‹¤.'}\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì´ˆê¸°í™” (temperature=0.5ë¡œ ì„¤ì •í•´ ì¼ê´€ì„± ìˆëŠ” ì¶œë ¥)\n",
    "#model = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë¦¬ë·° ë°ì´í„°\n",
    "review = \"\"\"\n",
    "ì´ ìŠ¤ë§ˆíŠ¸í°ì€ ë°°í„°ë¦¬ ìˆ˜ëª…ì´ ì •ë§ ì¢‹ì•„ì„œ í•˜ë£¨ ì¢…ì¼ ì‚¬ìš©í•´ë„ ì¶©ì „ì´ í•„ìš” ì—†ì—ˆì–´ìš”. \n",
    "ì¹´ë©”ë¼ í™”ì§ˆë„ ì„ ëª…í•˜ê³ , íŠ¹íˆ ì•¼ê°„ ëª¨ë“œê°€ í›Œë¥­í•©ë‹ˆë‹¤. \n",
    "ë‹¤ë§Œ ê°€ê²©ì´ ì¡°ê¸ˆ ë¹„ì‹¸ê³ , ë¬´ê²Œê°€ 200gì´ ë„˜ì–´ì„œ ì†ì´ í”¼ê³¤í•  ìˆ˜ ìˆì–´ìš”.\n",
    "\"\"\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "chain = prompt | model | parser\n",
    "\n",
    "output = chain.invoke({\"review\": review})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥ (Pretty Print)\n",
    "print(\"===== ë¶„ì„ ê²°ê³¼ =====\")\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b22a59",
   "metadata": {},
   "source": [
    "### DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2dadc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-13 14:43:03.155562\n"
     ]
    }
   ],
   "source": [
    "# ë‘˜ ì¤‘ í•˜ë‚˜ ì„¤ì¹˜ì¹˜\n",
    "#%pip install python-dateutil\n",
    "#poetry add python-dateutil\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3e49c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‚ ì§œ ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­:\n",
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 1182-12-17T20:07:21.928185Z, 0964-10-02T23:21:39.751011Z, 0475-01-29T03:51:49.318157Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "source": [
    "# ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™” (ì‹œê°„ëŒ€ í¬í•¨ ê°€ëŠ¥)\n",
    "datetime_parser = DatetimeOutputParser()\n",
    "format_instructions = datetime_parser.get_format_instructions()\n",
    "\n",
    "print(\"ë‚ ì§œ ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­:\")\n",
    "print(format_instructions)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "# í˜„ì¬ ë‚ ì§œë¥¼ ëª…ì‹œì ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "template = f\"\"\"\n",
    "í˜„ì¬ ë‚ ì§œ: {current_date}\n",
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ/ì‹œê°„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. ìƒëŒ€ì  í‘œí˜„(ì˜ˆ: 'ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼')ì€ í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "í…ìŠ¤íŠ¸: {{text}}\n",
    "\n",
    "{{format_instructions}}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75d24d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: íšŒì˜ëŠ” 2025ë…„ 6ì›” 15ì¼ ì˜¤í›„ 2ì‹œì— ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "ì¶”ì¶œëœ ë‚ ì§œ: 2025-06-15 14:00:00 \n",
      "\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: í”„ë¡œì íŠ¸ ë§ˆê°ì¼ì€ ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼ì…ë‹ˆë‹¤.\n",
      "ì¶”ì¶œëœ ë‚ ì§œ: 2025-06-20 00:00:00 \n",
      "\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: í–‰ì‚¬ ì‹œì‘: 7/25/2025 18:00 KST\n",
      "ì¶”ì¶œëœ ë‚ ì§œ: 2025-07-25 18:00:00 \n",
      "\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: 3ì¼ í›„ì— ì‹œìŠ¤í…œ ì ê²€ì´ ì§„í–‰ë©ë‹ˆë‹¤.\n",
      "ì¶”ì¶œëœ ë‚ ì§œ: 2025-06-16 00:00:00 \n",
      "í˜„ì¬ ë‚ ì§œ: 2025-06-13\n",
      "\n",
      "í…ìŠ¤íŠ¸ì—ì„œ ì´ë²¤íŠ¸ ë‚ ì§œ ì¶”ì¶œ:\n",
      "\n",
      "- í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë§ˆì¼“: 2024-12-10\n",
      "- í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ì´ë¸Œ íŒŒí‹°: 2024-12-24\n",
      "- ìƒˆí•´ ì¹´ìš´íŠ¸ë‹¤ìš´: 2025-01-01 00:00:00\n",
      "\n",
      "ì¶œë ¥:\n",
      "\n",
      "- ì´ë²¤íŠ¸ëª…: í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë§ˆì¼“\n",
      "- ë‚ ì§œ: 2024-12-10 00:00:00\n",
      "\n",
      "- ì´ë²¤íŠ¸ëª…: í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ì´ë¸Œ íŒŒí‹°\n",
      "- ë‚ ì§œ: 2024-12-24 00:00:00\n",
      "\n",
      "- ì´ë²¤íŠ¸ëª…: ìƒˆí•´ ì¹´ìš´íŠ¸ë‹¤ìš´\n",
      "- ë‚ ì§œ: 2025-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì´ˆê¸°í™” (temperature=0.1ë¡œ ì„¤ì •í•´ ì •í™•í•œ ë‚ ì§œ ì¶œë ¥ ê°•ì¡°)\n",
    "#model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° (ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ í¬í•¨)\n",
    "texts = [\n",
    "    \"íšŒì˜ëŠ” 2025ë…„ 6ì›” 15ì¼ ì˜¤í›„ 2ì‹œì— ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\",\n",
    "    \"í”„ë¡œì íŠ¸ ë§ˆê°ì¼ì€ ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼ì…ë‹ˆë‹¤.\",\n",
    "    \"í–‰ì‚¬ ì‹œì‘: 7/25/2025 18:00 KST\",\n",
    "    \"3ì¼ í›„ì— ì‹œìŠ¤í…œ ì ê²€ì´ ì§„í–‰ë©ë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥\n",
    "chain = prompt | model | datetime_parser\n",
    "\n",
    "for text in texts:\n",
    "    print(f\"\\nì›ë³¸ í…ìŠ¤íŠ¸: {text}\")\n",
    "    output = chain.invoke({\"text\": text})\n",
    "    print(f\"ì¶”ì¶œëœ ë‚ ì§œ: {output.strftime('%Y-%m-%d %H:%M:%S %Z')}\")\n",
    "\n",
    "    \n",
    "# ì´ë²¤íŠ¸ ì¶”ì¶œìš© í”„ë¡¬í”„íŠ¸\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "event_template = \"\"\"\n",
    "í˜„ì¬ ë‚ ì§œ: {current_date}\n",
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ì´ë²¤íŠ¸ì˜ ë‚ ì§œ/ì‹œê°„ì„ ì¶”ì¶œí•˜ì„¸ìš”. ê° ì´ë²¤íŠ¸ëŠ” ì´ë¦„ê³¼ ë‚ ì§œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "ê° ì´ë²¤íŠ¸ì˜ ë‚ ì§œëŠ” í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "í…ìŠ¤íŠ¸: {text}\n",
    "\n",
    "ì¶œë ¥ í˜•ì‹:\n",
    "- ì´ë²¤íŠ¸ëª…: [ì´ë¦„]\n",
    "- ë‚ ì§œ: [YYYY-MM-DD HH:MM:SS]\n",
    "\"\"\"\n",
    "\n",
    "event_prompt = ChatPromptTemplate.from_template(event_template)\n",
    "event_chain = event_prompt | model\n",
    "\n",
    "# ì˜ˆì‹œ í…ìŠ¤íŠ¸ (ì—¬ëŸ¬ ì´ë²¤íŠ¸ í¬í•¨)\n",
    "event_text = \"\"\"\n",
    "12ì›” 10ì¼ì— í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë§ˆì¼“ì´ ì—´ë¦¬ê³ , 12ì›” 24ì¼ì—ëŠ” í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ì´ë¸Œ íŒŒí‹°ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "ë˜í•œ 1ì›” 1ì¼ 00:00ì— ìƒˆí•´ ì¹´ìš´íŠ¸ë‹¤ìš´ì´ ì§„í–‰ë  ì˜ˆì •ì…ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "print(event_chain.invoke({\"current_date\":current_date, \"text\": event_text}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba9f59",
   "metadata": {},
   "source": [
    "### EnumOutputParser + OutputFixingParser(ë„ ì‚¬ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "195ad2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import EnumOutputParser, OutputFixingParser\n",
    "from langchain.schema import OutputParserException\n",
    "\n",
    "from enum import Enum\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "284c9631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°ì • ë¶„ë¥˜ ì¶œë ¥ í˜•ì‹:\n",
      "Select one of the following options: ê¸ì •, ë¶€ì •, ì¤‘ë¦½\n",
      "ëª¨ë¸ ë° íŒŒì„œ ì„¤ì • ì™„ë£Œ\n",
      "í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸ 7ê°œ ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ê°ì • í´ë˜ìŠ¤ ì •ì˜ (Enum)\n",
    "class Sentiment(str, Enum):\n",
    "    POSITIVE = \"ê¸ì •\"\n",
    "    NEGATIVE = \"ë¶€ì •\"\n",
    "    NEUTRAL = \"ì¤‘ë¦½\"\n",
    "\n",
    "# EnumOutputParser ì´ˆê¸°í™”\n",
    "parser = EnumOutputParser(enum=Sentiment)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "print(\"ê°ì • ë¶„ë¥˜ ì¶œë ¥ í˜•ì‹:\")\n",
    "print(format_instructions)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "template = \"\"\"\n",
    "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ê³ , ë°˜ë“œì‹œ ì•„ë˜ ì„¸ ê°€ì§€ ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "í…ìŠ¤íŠ¸: \"{text}\"\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "ì¤‘ìš” ê·œì¹™:\n",
    "1. ë°˜ë“œì‹œ \"ê¸ì •\", \"ë¶€ì •\", \"ì¤‘ë¦½\" ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\n",
    "2. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¶€ê°€ ì„¤ëª…ì„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”\n",
    "3. ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ë¬¸ìë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”\n",
    "4. ì˜¤ì§ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)   \n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0  # ì¼ê´€ì„±ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •\n",
    ")\n",
    "\n",
    "# OutputFixingParserë¡œ ì•ˆì •ì„± í–¥ìƒ\n",
    "fixing_parser = OutputFixingParser.from_llm(parser=parser, llm=model)\n",
    "\n",
    "print(\"ëª¨ë¸ ë° íŒŒì„œ ì„¤ì • ì™„ë£Œ\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸\n",
    "texts = [\n",
    "    \"ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”! ì™„ì „ ë§Œì¡±ìŠ¤ëŸ¬ì›Œìš”.\",\n",
    "    \"ì„œë¹„ìŠ¤ê°€ ë„ˆë¬´ ëŠë¦¬ê³  ë¶ˆì¹œì ˆí–ˆìŠµë‹ˆë‹¤.\",\n",
    "    \"ì˜¤ëŠ˜ì€ ë¹„ê°€ ì˜¨ë‹¤ë„¤ìš”.\",\n",
    "    \"ë°°ì†¡ì€ ë¹ ë¥´ì§€ë§Œ í’ˆì§ˆì´ ì•„ì‰½ìŠµë‹ˆë‹¤.\",\n",
    "    \"ìµœê³ ì˜ ê²½í—˜ì´ì—ˆìŠµë‹ˆë‹¤!\",\n",
    "    \"ì™„ì „ ì‹¤ë§í–ˆì–´ìš”... ìµœì•…ì´ì—ìš”\",\n",
    "    \"ì¼ì´ ë„ˆë¬´ ë§ì•„ì„œ ë°¤ì„ ìƒœì–´ìš”\"\n",
    "]\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸ {len(texts)}ê°œ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3db71f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì‹¤ì œ ê°ì • ë¶„ì„ ê²°ê³¼ ===\n",
      "\n",
      "1. í…ìŠ¤íŠ¸: ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”! ì™„ì „ ë§Œì¡±ìŠ¤ëŸ¬ì›Œìš”.\n",
      "   ê°ì •: ê¸ì • \n",
      "\n",
      "2. í…ìŠ¤íŠ¸: ì„œë¹„ìŠ¤ê°€ ë„ˆë¬´ ëŠë¦¬ê³  ë¶ˆì¹œì ˆí–ˆìŠµë‹ˆë‹¤.\n",
      "   ê°ì •: ë¶€ì • \n",
      "\n",
      "3. í…ìŠ¤íŠ¸: ì˜¤ëŠ˜ì€ ë¹„ê°€ ì˜¨ë‹¤ë„¤ìš”.\n",
      "   ê°ì •: ì¤‘ë¦½ \n",
      "\n",
      "4. í…ìŠ¤íŠ¸: ë°°ì†¡ì€ ë¹ ë¥´ì§€ë§Œ í’ˆì§ˆì´ ì•„ì‰½ìŠµë‹ˆë‹¤.\n",
      "   ê°ì •: ë¶€ì • \n",
      "\n",
      "5. í…ìŠ¤íŠ¸: ìµœê³ ì˜ ê²½í—˜ì´ì—ˆìŠµë‹ˆë‹¤!\n",
      "   ê°ì •: ê¸ì • \n",
      "\n",
      "6. í…ìŠ¤íŠ¸: ì™„ì „ ì‹¤ë§í–ˆì–´ìš”... ìµœì•…ì´ì—ìš”\n",
      "   ê°ì •: ë¶€ì • \n",
      "\n",
      "7. í…ìŠ¤íŠ¸: ì¼ì´ ë„ˆë¬´ ë§ì•„ì„œ ë°¤ì„ ìƒœì–´ìš”\n",
      "   ê°ì •: ë¶€ì • \n",
      "\n",
      "=== ê²°ê³¼ ìš”ì•½ ===\n",
      "ì„±ê³µ: 7/7 (100.0%)\n",
      "ì‹¤íŒ¨: 0/7\n"
     ]
    }
   ],
   "source": [
    "# ì•ˆì „í•œ ê°ì • ë¶„ì„ í•¨ìˆ˜ (ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)\n",
    "def safe_sentiment_analysis(text, use_fixing_parser=True):\n",
    "    \"\"\"ì•ˆì „í•œ ê°ì • ë¶„ì„ í•¨ìˆ˜ - ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨\"\"\"\n",
    "    try:\n",
    "        # ê¸°ë³¸ ì²´ì¸ ìƒì„±\n",
    "        chain = prompt | model | (fixing_parser if use_fixing_parser else parser)\n",
    "        \n",
    "        # ë¶„ì„ ì‹¤í–‰\n",
    "        result = chain.invoke({\"text\": text})\n",
    "        return result, None\n",
    "        \n",
    "    except OutputParserException as e:\n",
    "        return None, f\"íŒŒì‹± ì˜¤ë¥˜: {str(e)[:100]}...\"\n",
    "    except Exception as e:\n",
    "        return None, f\"ì¼ë°˜ ì˜¤ë¥˜: {str(e)[:100]}...\"\n",
    "\n",
    "# ì‹¤ì œ ê°ì • ë¶„ì„ ì‹¤í–‰ (API í‚¤ í•„ìš”)\n",
    "def run_sentiment_analysis():\n",
    "    \"\"\"ì‹¤ì œ ê°ì • ë¶„ì„ ì‹¤í–‰\"\"\"\n",
    "    print(\"=== ì‹¤ì œ ê°ì • ë¶„ì„ ê²°ê³¼ ===\")\n",
    "    \n",
    "    success_count = 0\n",
    "    total_count = len(texts)\n",
    "    \n",
    "    for i, text in enumerate(texts, 1):\n",
    "        print(f\"\\n{i}. í…ìŠ¤íŠ¸: {text}\")\n",
    "        \n",
    "        # OutputFixingParser ì‚¬ìš©\n",
    "        result, error = safe_sentiment_analysis(text, use_fixing_parser=True)\n",
    "        \n",
    "        if result:\n",
    "            print(f\"   ê°ì •: {result.value} \")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"   ì˜¤ë¥˜: {error} \")\n",
    "            \n",
    "            # ê¸°ë³¸ íŒŒì„œë¡œ ì¬ì‹œë„\n",
    "            print(\"   ê¸°ë³¸ íŒŒì„œë¡œ ì¬ì‹œë„...\")\n",
    "            result2, error2 = safe_sentiment_analysis(text, use_fixing_parser=False)\n",
    "            \n",
    "            if result2:\n",
    "                print(f\"   ê°ì •: {result2.value} (ê¸°ë³¸ íŒŒì„œ ì„±ê³µ)\")\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"   ì¬ì‹œë„ ì‹¤íŒ¨: {error2} \")\n",
    "    \n",
    "    print(f\"\\n=== ê²°ê³¼ ìš”ì•½ ===\")\n",
    "    print(f\"ì„±ê³µ: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)\")\n",
    "    print(f\"ì‹¤íŒ¨: {total_count-success_count}/{total_count}\")\n",
    "\n",
    "# ì‹¤ì œ ë¶„ì„ ì‹¤í–‰ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)\n",
    "try:\n",
    "    run_sentiment_analysis()\n",
    "except Exception as e:\n",
    "    print(\"API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜:\")\n",
    "    print(\"ì‹¤ì œ ì‹¤í–‰ì„ ìœ„í•´ì„œëŠ” OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.\")\n",
    "    print(f\"ì˜¤ë¥˜ ìƒì„¸: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbcd918",
   "metadata": {},
   "source": [
    "### BooleanOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe934426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['applicant_details', 'min_age', 'min_credit_score', 'min_income'] input_types={} partial_variables={'format_instructions': '\\nì¶œë ¥ì€ ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤:\\n- `True`: ëª¨ë“  ì¡°ê±´ ì¶©ì¡± ì‹œ\\n- `False`: í•˜ë‚˜ë¼ë„ ì¡°ê±´ ë¶ˆì¶©ì¡± ì‹œ\\n\\nì˜ˆì‹œ:\\nTrue  # ëª¨ë“  ì¡°ê±´ ë§Œì¡±\\nFalse # ì¡°ê±´ ë¶ˆë§Œì¡±\\n'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['applicant_details', 'format_instructions', 'min_age', 'min_credit_score', 'min_income'], input_types={}, partial_variables={}, template='\\në‹¤ìŒ ëŒ€ì¶œ ì‹ ì²­ìë¥¼ í‰ê°€í•˜ì„¸ìš”. ì¡°ê±´ì„ ëª¨ë‘ ì¶©ì¡±í•˜ë©´ `True`, ì•„ë‹ˆë©´ `False`ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.\\n\\n### ì¡°ê±´:\\n1. ë‚˜ì´ >= {min_age}ì„¸\\n2. ì‹ ìš© ì ìˆ˜ >= {min_credit_score}\\n3. ì›” ìˆ˜ì… >= ${min_income}\\n\\n### ì‹ ì²­ì ì •ë³´:\\n{applicant_details}\\n\\n{format_instructions}\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import BooleanOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Boolean íŒŒì„œ ì´ˆê¸°í™”\n",
    "boolParser = BooleanOutputParser()\n",
    "\n",
    "# ìˆ˜ë™ìœ¼ë¡œ í¬ë§· ì§€ì‹œì‚¬í•­ ì •ì˜ (LangChain ë²„ì „ ì´ìŠˆ íšŒí”¼)\n",
    "format_instructions = \"\"\"\n",
    "ì¶œë ¥ì€ ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤:\n",
    "- `True`: ëª¨ë“  ì¡°ê±´ ì¶©ì¡± ì‹œ\n",
    "- `False`: í•˜ë‚˜ë¼ë„ ì¡°ê±´ ë¶ˆì¶©ì¡± ì‹œ\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "True  # ëª¨ë“  ì¡°ê±´ ë§Œì¡±\n",
    "False # ì¡°ê±´ ë¶ˆë§Œì¡±\n",
    "\"\"\"\n",
    "\n",
    "# ìŠ¹ì¸/ê±°ë¶€ ê²°ì • í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "template = \"\"\"\n",
    "ë‹¤ìŒ ëŒ€ì¶œ ì‹ ì²­ìë¥¼ í‰ê°€í•˜ì„¸ìš”. ì¡°ê±´ì„ ëª¨ë‘ ì¶©ì¡±í•˜ë©´ `True`, ì•„ë‹ˆë©´ `False`ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "### ì¡°ê±´:\n",
    "1. ë‚˜ì´ >= {min_age}ì„¸\n",
    "2. ì‹ ìš© ì ìˆ˜ >= {min_credit_score}\n",
    "3. ì›” ìˆ˜ì… >= ${min_income}\n",
    "\n",
    "### ì‹ ì²­ì ì •ë³´:\n",
    "{applicant_details}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2257fde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜¤ë¥˜ ë°œìƒ: BooleanOutputParser expected output value to include either YES or NO. Received ### ëŒ€ì¶œ ì‹ ì²­ì í‰ê°€\n",
      "\n",
      "#### ì¡°ê±´:\n",
      "1. ë‚˜ì´ >= 18ì„¸\n",
      "2. ì‹ ìš© ì ìˆ˜ >= 700\n",
      "3. ì›” ìˆ˜ì… >= $3000\n",
      "\n",
      "#### ì‹ ì²­ì ì •ë³´:\n",
      "- ì´ë¦„: ê¹€ì² ìˆ˜\n",
      "- ë‚˜ì´: 25ì„¸\n",
      "- ì‹ ìš© ì ìˆ˜: 750\n",
      "- ì›” ìˆ˜ì…: $3,500\n",
      "\n",
      "### í‰ê°€ ì½”ë“œ\n",
      "\n",
      "```python\n",
      "def evaluate_loan_application(name, age, credit_score, monthly_income):\n",
      "    # ì¡°ê±´ 1: ë‚˜ì´ >= 18ì„¸\n",
      "    condition1 = age >= 18\n",
      "    \n",
      "    # ì¡°ê±´ 2: ì‹ ìš© ì ìˆ˜ >= 700\n",
      "    condition2 = credit_score >= 700\n",
      "    \n",
      "    # ì¡°ê±´ 3: ì›” ìˆ˜ì… >= $3000\n",
      "    condition3 = monthly_income >= 3000\n",
      "    \n",
      "    # ëª¨ë“  ì¡°ê±´ ì¶©ì¡± ì‹œ True ë°˜í™˜\n",
      "    return condition1 and condition2 and condition3\n",
      "\n",
      "# ì‹ ì²­ì ì •ë³´\n",
      "name = \"ê¹€ì² ìˆ˜\"\n",
      "age = 25\n",
      "credit_score = 750\n",
      "monthly_income = 3500\n",
      "\n",
      "# í‰ê°€ ê²°ê³¼\n",
      "result = evaluate_loan_application(name, age, credit_score, monthly_income)\n",
      "\n",
      "print(result)  # True\n",
      "```\n",
      "\n",
      "### ê²°ê³¼\n",
      "```\n",
      "True\n",
      "```\n",
      "\n",
      "### ì„¤ëª…\n",
      "\n",
      "- ëª¨ë“  ì¡°ê±´ì„ ì¶©ì¡±í•˜ë¯€ë¡œ `True`ê°€ ì¶œë ¥ë©ë‹ˆë‹¤. \n",
      "\n",
      "1. ë‚˜ì´: 25ì„¸ >= 18ì„¸ (ì¶©ì¡±)\n",
      "2. ì‹ ìš© ì ìˆ˜: 750 >= 700 (ì¶©ì¡±)\n",
      "3. ì›” ìˆ˜ì…: $3,500 >= $3,000 (ì¶©ì¡±)\n",
      "\n",
      "ë”°ë¼ì„œ ëŒ€ì¶œ ì‹ ì²­ìì˜ ì¡°ê±´ì€ ëª¨ë‘ ë§Œì¡±í•˜ë¯€ë¡œ `True`ì…ë‹ˆë‹¤..\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "chain = prompt | model | boolParser\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤\n",
    "test_cases = [\n",
    "    {\n",
    "        \"min_age\": 18,\n",
    "        \"min_credit_score\": 700,\n",
    "        \"min_income\": 3000,\n",
    "        \"applicant_details\": \"\"\"\n",
    "        - ì´ë¦„: ê¹€ì² ìˆ˜\n",
    "        - ë‚˜ì´: 25ì„¸\n",
    "        - ì‹ ìš© ì ìˆ˜: 750\n",
    "        - ì›” ìˆ˜ì…: $3,500\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"min_age\": 18,\n",
    "        \"min_credit_score\": 700,\n",
    "        \"min_income\": 3000,\n",
    "        \"applicant_details\": \"\"\"\n",
    "        - ì´ë¦„: ì´ì˜í¬\n",
    "        - ë‚˜ì´: 17ì„¸\n",
    "        - ì‹ ìš© ì ìˆ˜: 680\n",
    "        - ì›” ìˆ˜ì…: $2,800\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ê±°ë¶€ ì‚¬ìœ  ìƒì„± í”„ë¡¬í”„íŠ¸ (ì¶œë ¥ í˜•ì‹ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •)\n",
    "reason_template = \"\"\"\n",
    "ë‹¤ìŒ ëŒ€ì¶œ ì‹ ì²­ ê±°ë¶€ ì‚¬ìœ ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”. ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "[ê±°ë¶€ ì‚¬ìœ ]: [ì‚¬ìœ  ë‚´ìš©]\n",
    "\n",
    "### ì‹ ì²­ì ì •ë³´:\n",
    "{applicant_details}\n",
    "\n",
    "### ì¡°ê±´:\n",
    "- ìµœì†Œ ë‚˜ì´: {min_age}ì„¸\n",
    "- ìµœì†Œ ì‹ ìš© ì ìˆ˜: {min_credit_score}\n",
    "- ìµœì†Œ ì›” ìˆ˜ì…: ${min_income}\n",
    "\"\"\"\n",
    "reason_prompt = ChatPromptTemplate.from_template(reason_template)\n",
    "reason_chain = reason_prompt | model | StrOutputParser()\n",
    "\n",
    "# ì²´ì¸ í™•ì¥ (Boolean íŒŒì„œì™€ ë¶„ë¦¬)\n",
    "def get_decision_with_reason(input_dict):\n",
    "    # 1. ë¨¼ì € Boolean ê²°ì •\n",
    "    decision = chain.invoke(input_dict)\n",
    "    \n",
    "    # 2. ê±°ë¶€ ì‹œì—ë§Œ ì‚¬ìœ  ìƒì„±\n",
    "    if not decision:\n",
    "        try:\n",
    "            reason = reason_chain.invoke({\n",
    "                \"applicant_details\": input_dict[\"applicant_details\"],\n",
    "                \"min_age\": input_dict[\"min_age\"],\n",
    "                \"min_credit_score\": input_dict[\"min_credit_score\"],\n",
    "                \"min_income\": input_dict[\"min_income\"]\n",
    "            })\n",
    "            return decision, reason\n",
    "        except Exception as e:\n",
    "            return decision, f\"ê±°ë¶€ ì‚¬ìœ  ìƒì„± ì‹¤íŒ¨: {str(e)}\"\n",
    "    return decision, \"ëª¨ë“  ì¡°ê±´ì„ ì¶©ì¡±í–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ (ì•ˆì „í•œ ì‹¤í–‰)\n",
    "try:\n",
    "    decision, reason = get_decision_with_reason(test_cases[0])\n",
    "    print(f\"\\nê²°ê³¼: {'ìŠ¹ì¸' if decision else 'ê±°ë¶€'}\")\n",
    "    print(f\"ì‚¬ìœ : {reason}\")\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
