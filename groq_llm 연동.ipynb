{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6b7696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32dcb62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "473dc1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"human\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"LangServe 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94f6e9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001F2F765AC30> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F2F744E360> root_client=<openai.OpenAI object at 0x000001F2F6C742F0> root_async_client=<openai.AsyncOpenAI object at 0x000001F2F76879B0> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a90e8848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답: LangServe는 개발자가 대규모 언어 모델(LLM)을 쉽게 배포하고 관리할 수 있도록 도와주는 플랫폼입니다. LangServe를 사용하면 개발자는 LLM을 API로 감싸서 쉽게 사용할 수 있으며, 대규모 언어 모델을 기반으로 하는 애플리케이션을 빠르게 개발하고 배포할 수 있습니다.\n",
      "\n",
      "LangServe의 주요 기능은 다음과 같습니다:\n",
      "\n",
      "1. **LLM 배포**: LangServe를 사용하면 개발자는 훈련된 LLM을 쉽게 배포할 수 있습니다. LangServe는 다양한 LLM 프레임워크를 지원하며, 개발자는 자신의 모델을 LangServe에 업로드하고 배포할 수 있습니다.\n",
      "\n",
      "2. **API 제공**: LangServe는 LLM을 API로 감싸서 제공합니다. 이를 통해 개발자는 애플리케이션에서 LLM을 쉽게 호출하고 사용할 수 있습니다.\n",
      "\n",
      "3. **자동 확장**: LangServe는 자동으로 확장되는 인프라를 제공합니다. 따라서 대규모 트래픽이 발생하더라도 LangServe는 자동으로 자원을 할당하고 확장하여 안정적인 서비스를 제공합니다.\n",
      "\n",
      "4. **모니터링 및 로그**: LangServe는 LLM의 성능과 사용량을 모니터링하고 로그를 수집합니다. 이를 통해 개발자는 모델의 성능을 분석하고 최적화할 수 있습니다.\n",
      "\n",
      "5. **보안**: LangServe는 데이터 암호화, 접근 제어 등 강력한 보안 기능을 제공합니다. 이를 통해 개발자는 민감한 데이터를 안전하게 보호할 수 있습니다.\n",
      "\n",
      "6. **다양한 LLM 지원**: LangServe는 다양한 LLM 프레임워크를 지원합니다. 예를 들어, Hugging Face Transformers, TensorFlow, PyTorch 등 다양한 프레임워크를 지원하며, 개발자는 자신의 모델을 쉽게 배포할 수 있습니다.\n",
      "\n",
      "LangServe를 사용하면 개발자는 대규모 언어 모델을 기반으로 하는 애플리케이션을 빠르게 개발하고 배포할 수 있습니다. LangServe는 개발자가 LLM을 쉽게 사용하고 관리할 수 있도록 도와주며, 대규모 언어 모델을 기반으로 하는 서비스의 개발과 배포를 가속화합니다.\n",
      "\n",
      "예를 들어, LangServe를 사용하여 다음과 같은 애플리케이션을 개발할 수 있습니다:\n",
      "\n",
      "* 챗봇: LangServe를 사용하여 자연어 처리 기반의 챗봇을 개발할 수 있습니다.\n",
      "* 언어 번역: LangServe를 사용하여 언어 번역 애플리케이션을 개발할 수 있습니다.\n",
      "* 텍스트 요약: LangServe를 사용하여 긴 문서의 요약을 자동으로 생성하는 애플리케이션을 개발할 수 있습니다.\n",
      "\n",
      "LangServe는 대규모 언어 모델을 기반으로 하는 다양한 애플리케이션에 사용할 수 있으며, 개발자는 LangServe를 사용하여 빠르게 애플리케이션을 개발하고 배포할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ce57ca",
   "metadata": {},
   "source": [
    "### LCEL (Prompt + LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a6b074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0d18a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a0369",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM + OutputParser를 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2407eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain 연결 (LCEL) prompt + llm + outputparser\n",
    "output_parser = StrOutputParser()\n",
    "chain2 = prompt | llm | output_parser\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7594b4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "인공지능 모델의 학습 원리는 데이터를 기반으로 모델이 스스로 학습하고 개선하는 과정입니다. 여기에는 여러 단계와 개념이 포함됩니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해서는 관련된 데이터가 필요합니다. 이 데이터는 문제의 성격에 따라 달라지며, 이미지, 텍스트, 오디오 등 다양한 형태일 수 있습니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집된 데이터는 학습에 적합한 형태로 변환되어야 합니다. 여기에는 데이터 정리, 노이즈 제거, 데이터 변환 등의 작업이 포함됩니다.\n",
      "\n",
      "3. **모델 선택**: 학습에 사용할 인공지능 모델을 선택합니다. 모델의 종류는 문제의 성격과 데이터의 유형에 따라 결정되며, 신경망, 결정 트리, 서포트 벡터 머신 등 다양한 모델이 있습니다.\n",
      "\n",
      "4. **학습**: 선택된 모델에 데이터를 입력하여 모델을 학습시킵니다. 이 과정에서는 모델이 데이터로부터 패턴이나 관계를 발견하고, 이를 기반으로 예측이나 분류를 수행할 수 있도록 합니다. 학습에는 지도 학습, 비지도 학습, 강화 학습 등이 있습니다.\n",
      "\n",
      "   - **지도 학습**: 레이블이 붙어 있는 데이터를 사용하여 모델이 입력 데이터로부터 출력을 예측하도록 학습하는 방법입니다. 예로는 이미지 분류, 음성 인식 등이 있습니다.\n",
      "\n",
      "   - **비지도 학습**: 레이블이 없는 데이터를 사용하여 모델이 데이터의 패턴이나 구조를 발견하도록 학습하는 방법입니다. 예로는 클러스터링, 차원 축소 등이 있습니다.\n",
      "\n",
      "   - **강화 학습**: 에이전트가 환경과 상호작용하며 보상을 최대화하는 정책을 학습하는 방법입니다. 예로는 게임 플레이, 로봇 제어 등이 있습니다.\n",
      "\n",
      "5. **평가**: 학습된 모델의 성능을 평가합니다. 이를 통해 모델이 얼마나 잘 학습되었고, 실제 문제에 적용될 수 있는지 판단합니다.\n",
      "\n",
      "6. **튜닝 및 최적화**: 모델의 성능을 개선하기 위해 하이퍼파라미터를 조정하거나 모델 구조를 변경하는 등의 최적화 작업을 수행합니다.\n",
      "\n",
      "7. **배포**: 최종적으로 학습된 모델을 실제 환경에 배포하여 사용합니다.\n",
      "\n",
      "인공지능 모델의 학습 원리는 반복적인 개선과 평가를 통해 모델의 성능을 향상시키는 것입니다. 이를 통해 모델은 주어진 문제에 대해 더 정확하고 효율적인 솔루션을 제공할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "331c679c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LangChain은 다양한 AI 관련 제품을 제공하는 회사입니다. LangChain의 주요 제품은 다음과 같습니다:\n",
      "\n",
      "1. **LangSmith**: LangSmith는 개발자가 LangChain을 사용하여 애플리케이션을 더 쉽게 구축하고 디버깅하며 모니터링할 수 있도록 지원하는 개발 플랫폼입니다. LangSmith를 사용하면 개발자는 LangChain 모델을 더 효율적으로 관리하고, 애플리케이션의 성능을 모니터링하며, 문제가 발생했을 때 빠르게 디버깅할 수 있습니다.\n",
      "\n",
      "2. **LangServe**: LangServe는 LangChain 모델을 쉽게 배포하고 관리할 수 있도록 지원하는 제품입니다. LangServe를 사용하면 개발자는 LangChain 모델을 API로 쉽게 변환하고, 이를 통해 다양한 애플리케이션에 모델을 통합할 수 있습니다. LangServe는 모델의 배포, 관리, 및 모니터링을 간소화합니다.\n",
      "\n",
      "3. **LangChain 자체**: LangChain은 기본적으로 대규모 언어 모델(LLM)을 활용하여 자연어 처리 작업을 지원하는 프레임워크입니다. LangChain은 개발자가 다양한 LLM을 쉽게 통합하고, 이를 기반으로 애플리케이션을 구축할 수 있도록 지원합니다.\n",
      "\n",
      "이러한 제품들은 LangChain이 개발자와 기업이 AI 애플리케이션을 더 쉽게 구축하고 관리할 수 있도록 지원하는 생태계의 일부입니다. 각 제품은 개발 과정의 특정 단계를 지원하며, LangChain의 전반적인 목표는 AI 기술의 접근성을 높이고, 개발자가 더 혁신적인 애플리케이션을 만들 수 있도록 돕는 것입니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \"LangChain의 Products(제품)는 어떤 것들이 있나요?? 예를 들어 LangSmith, LangServe 같은 Product가 있어요\"})\n",
    "    print(type(result))\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b1a4c1",
   "metadata": {},
   "source": [
    "### Runnable의 stream() 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a9cd2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 인공지능 모델의 학습 원리\n",
      "\n",
      "인공지능 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "### 1. 데이터 수집\n",
      "\n",
      "인공지능 모델을 학습시키기 위해서는 먼저 데이터가 필요합니다. 데이터는 모델이 학습할 수 있는 정보를 제공하며, 모델의 성능을 결정하는 중요한 요소입니다. 데이터는 크게 **라벨링된 데이터**와 **비라벨링된 데이터**로 구분됩니다.\n",
      "\n",
      "*   라벨링된 데이터: 데이터에 라벨 또는 태그가 붙어 있는 데이터입니다. 예를 들어, 이미지 분류 모델을 학습시키기 위해 고양이, 강아지, 자동차 등의 라벨이 붙어 있는 이미지 데이터가 있습니다.\n",
      "*   비라벨링된 데이터: 데이터에 라벨 또는 태그가 붙어 있지 않은 데이터입니다. 예를 들어, 자율 주행 자동차의 센서 데이터나 소셜 미디어의 텍스트 데이터가 있습니다.\n",
      "\n",
      "### 2. 데이터 전처리\n",
      "\n",
      "수집된 데이터는 모델에 입력하기 전에 **전처리**가 필요합니다. 전처리 과정은 데이터를 정제하고 변환하여 모델이 학습하기에 적합한 형태로 만드는 과정입니다. 예를 들어, 이미지 데이터의 경우 이미지의 크기를 조정하거나 노이즈를 제거하는 과정이 있습니다.\n",
      "\n",
      "### 3. 모델 선택\n",
      "\n",
      "적합한 모델을 선택하는 과정입니다. 모델의 종류로는 신경망, 의사결정 트리, 서포트 벡터 머신 등이 있습니다. 각 모델은 고유한 특성과 장단점이 있으며, 문제의 성격과 데이터의 유형에 따라 적합한 모델을 선택해야 합니다.\n",
      "\n",
      "### 4. 모델 학습\n",
      "\n",
      "모델을 학습시키는 과정입니다. 학습 과정에서는 모델에 데이터를 입력하고, 모델이 데이터를 분석하여 학습합니다. 이 과정에서는 **손실 함수**와 **최적화 알고리즘**이 사용됩니다.\n",
      "\n",
      "*   손실 함수: 모델의 예측 결과와 실제 값 사이의 차이를 측정하는 함수입니다. 손실 함수는 모델의 성능을 평가하는 데 사용됩니다. 예를 들어, 선형 회귀 모델에서는 평균 제곱 오차(MSE)를 손실 함수로 사용합니다.\n",
      "*   최적화 알고리즘: 모델의 가중치를 조정하여 손실 함수를 최소화하는 알고리즘입니다. 최적화 알고리즘에는 경사 하강법, Adam, RMSprop 등이 있습니다.\n",
      "\n",
      "### 5. 모델 평가\n",
      "\n",
      "학습된 모델의 성능을 평가하는 과정입니다. 모델 평가에서는 테스트 데이터를 사용하여 모델의 성능을 측정합니다. 평가 지표로는 정확도, 정밀도, 재현율, F1 점수 등이 있습니다.\n",
      "\n",
      "### 6. 모델 배포\n",
      "\n",
      "학습된 모델을 실제 환경에 배포하는 과정입니다. 모델 배포에서는 모델을 API나 웹 서비스로 감싸서 사용자가 쉽게 사용할 수 있도록 합니다.\n",
      "\n",
      "### 7. 모델 유지 보수\n",
      "\n",
      "배포된 모델을 지속적으로 유지 보수하는 과정입니다. 모델 유지 보수에서는 모델의 성능을 모니터링하고, 필요에 따라 모델을 업데이트하거나 재학습합니다.\n",
      "\n",
      "### 인공지능 모델 학습의 핵심 개념\n",
      "\n",
      "*   **과적합(Overfitting)**: 모델이 훈련 데이터에 너무 잘 맞아서 새로운 데이터에 대한 성능이 떨어지는 현상입니다. 과적합을 방지하기 위해서는 **정규화**나 **드롭아웃** 등의 기법을 사용할 수 있습니다.\n",
      "*   **과소적합(Underfitting)**: 모델이 훈련 데이터에 충분히 학습하지 못해서 성능이 떨어지는 현상입니다. 과소적합을 방지하기 위해서는 **데이터 증강**이나 **모델의 복잡도 증가** 등의 기법을 사용할 수 있습니다.\n",
      "\n",
      "### 인공지능 모델 학습의 예시\n",
      "\n",
      "*   **이미지 분류**: 이미지 데이터를 사용하여 객체를 분류하는 모델을 학습하는 예시입니다. 이미지 분류 모델은 이미지의 특징을 추출하여 객체를 분류합니다.\n",
      "*   **자연어 처리**: 텍스트 데이터를 사용하여 문장을 분류하거나 생성하는 모델을 학습하는 예시입니다. 자연어 처리 모델은 텍스트의 의미를 분석하여 문장을 분류하거나 생성합니다.\n",
      "\n",
      "### 인공지능 모델 학습의 중요성\n",
      "\n",
      "*   **데이터 기반 의사 결정**: 인공지능 모델은 데이터를 기반으로 의사 결정을 내릴 수 있습니다. 이는 비즈니스, 의료, 금융 등 다양한 분야에서 중요한 역할을 합니다.\n",
      "*   **자동화**: 인공지능 모델은 반복적인 작업을 자동화할 수 있습니다. 이는 생산성을 향상시키고 인적 오류를 줄일 수 있습니다.\n",
      "*   **혁신**: 인공지능 모델은 새로운 아이디어와 혁신을 이끌어낼 수 있습니다. 예를 들어, 이미지 생성 모델은 예술 작품을 생성하거나 새로운 디자인을 제안할 수 있습니다.\n",
      "\n",
      "인공지능 모델의 학습 원리는 데이터 수집, 데이터 전처리, 모델 선택, 모델 학습, 모델 평가, 모델 배포, 모델 유지 보수의 과정으로 이루어져 있습니다. 인공지능 모델 학습의 핵심 개념에는 과적합, 과소적합 등이 있으며, 이미지 분류, 자연어 처리 등의 예시가 있습니다. 인공지능 모델 학습은 데이터 기반 의사 결정, 자동화, 혁신 등의 중요성을 가지고 있습니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "try:\n",
    "    answer = chain2.stream({\"input\": \"인공지능 모델의 학습 원리를 자세하게 설명해 주세요.\"})\n",
    "    # 스트리밍 출력\n",
    "    # print(answer)\n",
    "    for token in answer:\n",
    "        # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "        print(token, end=\"\", flush=True)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063e41a2",
   "metadata": {},
   "source": [
    "### Multi Chain\n",
    "* 첫 번째 Chain의 출력이, 두 번째 Chain의 입력이 된다.\n",
    "* 두 개의 Chain과 Prompt + OutputParser를를 LCEL로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab0f4534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001F2F78068A0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F2F78069C0> root_client=<openai.OpenAI object at 0x000001F2F7806540> root_async_client=<openai.AsyncOpenAI object at 0x000001F2F7805CD0> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 한국 영화를 두 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추전한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 줄거리를 10문장으로 요약해 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf4e3541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  **사랑의 온도**: 이 영화는 두 주인공이 오랜 기간 동안 서로를 사랑하며, 서로에게 돌아오지 않을 것 같았던 사랑에 대한 이야기입니다. 이 영화는 로맨스 장르에서 매우 감동적인 작품 중 하나로 평가받고 있습니다.\n",
      "\n",
      "2.  **건축학개론**: 이 영화는 성장하는 두 남녀의 사랑과 이별을 다루는 영화입니다. 서로 처음 사랑했던 시절을 추억하며 사랑했던 사람에게 다시 다가가는 남자의 이야기는 많은 사람들이 공감할 수 있는 내용입니다.\n",
      "\n",
      "영화 제목: 사랑의 온도, 건축학개론 \n",
      "\n",
      "1.  **사랑의 온도**: \n",
      "    *   이 영화는 두 주인공이 오랜 기간 동안 서로를 사랑하며, 서로에게 돌아오지 않을 것 같았던 사랑에 대한 이야기입니다.\n",
      "    *   이 영화는 로맨스 장르에서 매우 감동적인 작품 중 하나로 평가받고 있습니다.\n",
      "    *   두 주인공은 서로에게 돌아오지 않을 것 같았던 사랑을 그리워하며, 서로에게 다가갑니다.\n",
      "    *   이 영화는 사랑과 이별에 대한 감동적인 이야기를 전달합니다.\n",
      "\n",
      "2.  **건축학개론**:\n",
      "    *   이 영화는 성장하는 두 남녀의 사랑과 이별을 다루는 영화입니다.\n",
      "    *   서로 처음 사랑했던 시절을 추억하며 사랑했던 사람에게 다시 다가가는 남자의 이야기는 많은 사람들이 공감할 수 있는 내용입니다.\n",
      "    *   이 영화는 성장과 사랑에 대한 이야기를 전달합니다.\n",
      "    *   두 주인공은 서로의 추억을 되살리며, 다시 사랑에 빠집니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "    chain2 = (\n",
    "        {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "        | prompt2\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "    response = chain2.invoke({\"genre\": \"로맨스\"})\n",
    "    print(response)  \n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64187e6e",
   "metadata": {},
   "source": [
    "### PromptTemplate 여러개 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "367b64f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the answers:\n",
      "\n",
      "**ChatGPT 모델의 학습 원리 요약 (3 문장)**\n",
      "\n",
      "ChatGPT는 대규모 언어 모델을 기반으로 하며, 수십억 개의 매개변수를 가진 신경망을 통해 학습합니다.\n",
      "이 모델은 다양한 텍스트 데이터를 학습하여 언어 패턴과 관계를 파악하고, 이를 통해 자연스러운 텍스트를 생성할 수 있습니다.\n",
      "ChatGPT는 강화 학습을 통해 사용자 피드백을 기반으로 모델을 지속적으로 개선하고 있습니다.\n",
      "\n",
      "**ChatGPT 모델의 장점 요약**\n",
      "\n",
      "* 자연스러운 대화 생성\n",
      "* 대규모 지식 데이터베이스 기반의 답변 제공\n",
      "* 지속적인 학습을 통한 모델 개선\n",
      "* 다양한 응용 분야에 활용 가능 (예: 고객 서비스, 언어 번역, 콘텐츠 생성)\n",
      "\n",
      "**비슷한 AI 모델**\n",
      "\n",
      "* LLaMA (Large Language Model Application)\n",
      "* BERT (Bidirectional Encoder Representations from Transformers)\n",
      "* RoBERTa (Robustly optimized BERT approach)\n",
      "* transformer-XL \n",
      "* XLNet \n",
      "\n",
      "Let me know if you need any further assistance!\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 요약하고 줄 바꿔서 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"영어\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"영어\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "679549e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 2 문장으로 한국어로 답변해 주세요.', 'Gemma 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'llama-4 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.']\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 2},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 3},\n",
    "    {\"model_name\": \"llama-4\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "826bdb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 모델은 대규모 텍스트 데이터를 학습하여 자연어 처리 능력을 향상시키는 인공지능 모델입니다. 이 모델은 주어진 문맥을 기반으로 다음에 나타날 문장을 예측하도록 학습되며, 수백만 개의 문장 쌍을 학습하여 언어 패턴과 관계를 파악합니다.\n",
      "Gemma는 컴퓨터가 자연어 작업을 수행하도록 훈련된 경량의 오픈 소스 언어 모델입니다. 대규모 언어 모델의 이점을 활용하면서 효율성을 극대화하도록 설계되었습니다. Gemma는 사전 학습된 모델 및 미세 조정된 모델의 형태로 제공되며 다양한 자연어 처리 작업에 즉시 사용할 수 있습니다.\n",
      "llama-4 모델은 메타에서 개발한 대규모 언어 모델입니다. 이 모델은 방대한 양의 텍스트 데이터를 학습하여 자연어 처리 능력을 키웁니다. 학습 과정에서 모델은 주어진 문맥에서 다음에 올 단어를 예측하도록 훈련되며, 이 과정을 통해 언어의 패턴과 구조를 학습합니다. 이를 통해 llama-4는 다양한 자연어 처리 작업에서 활용될 수 있는 성능을 발휘할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    # api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    response = llm.invoke(prompt) # AI 메시지\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eefc51b",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6e77a32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "## Definition \n",
      "\n",
      "딥러닝은 인공신경망을 기반으로 하는 머신러닝의 한 분야입니다. 딥러닝은 데이터의 패턴을 학습하고, 이를 바탕으로 예측이나 분류 작업을 수행합니다. 전통적인 머신러닝과 달리 딥러닝은 데이터의 특징을 자동으로 학습할 수 있어, 복잡한 데이터에서도 높은 성능을 발휘할 수 있습니다.\n",
      "\n",
      "## Key Concepts \n",
      "\n",
      "* **인공신경망**: 딥러닝의 핵심 개념으로, 인간의 뇌를 모방한 네트워크 구조입니다. 인공신경망은 입력층, 은닉층, 출력층으로 구성되며, 각 층은 여러 개의 노드로 이루어져 있습니다.\n",
      "* **심층 학습**: 딥러닝은 인공신경망의 깊이를 증가시켜, 데이터의 복잡한 패턴을 학습합니다. 이를 통해 딥러닝은 이미지, 음성, 자연어 처리 등 다양한 분야에서 뛰어난 성능을 발휘합니다.\n",
      "* **활성화 함수**: 인공신경망의 각 노드에서는 활성화 함수를 사용하여 출력값을 계산합니다. 대표적인 활성화 함수로는 sigmoid, ReLU, tanh 등이 있습니다.\n",
      "\n",
      "## Applications \n",
      "\n",
      "딥러닝은 다양한 분야에서 응용되고 있습니다. 몇 가지 예시는 다음과 같습니다.\n",
      "\n",
      "* **컴퓨터 비전**: 이미지 분류, 객체 탐지, 이미지 생성 등\n",
      "* **자연어 처리**: 언어 번역, 감정 분석, 챗봇 등\n",
      "* **음성 인식**: 음성 인식, 음성 합성 등\n",
      "\n",
      "## Conclusion \n",
      "\n",
      "딥러닝은 인공신경망을 기반으로 하는 머신러닝의 한 분야로, 데이터의 패턴을 학습하고 예측이나 분류 작업을 수행합니다. 딥러닝은 복잡한 데이터에서도 높은 성능을 발휘할 수 있어, 다양한 분야에서 응용되고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"당신은 {topic} 전문가입니다. 명확하고 자세하게 설명해주세요.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"딥러닝은 무엇인가요?\")\n",
    "\n",
    "# LLM 호출\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4d5e4",
   "metadata": {},
   "source": [
    "### FewShotPromptTemplate\n",
    "* 예시 제공 프롬프트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "191ec747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 태양계의 행성\n",
      "1. **수성**: 가장 작은 행성, 태양과 가깝습니다.\n",
      "2. **금성**: 매우 뜨겁고 밝은 행성입니다.\n",
      "3. **지구**: 생명체가 사는 유일한 행성입니다.\n",
      "4. **화성**: 붉은 행성으로, 로봇 탐사가 활발합니다.\n",
      "5. **목성**: 태양계에서 가장 큰 행성입니다.\n",
      "6. **토성**: 아름다운 고리를 가진 행성입니다.\n",
      "7. **천왕성**: 자전축이 기울어져 있습니다.\n",
      "8. **해왕성**: 태양계에서 가장 먼 행성입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = final_prompt | model\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"태양계의 행성들을 간략히 정리해 주세요.\"})\n",
    "#result = chain.invoke({\"input\": \"양자 얽힘이 무엇인가요?\"})\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
