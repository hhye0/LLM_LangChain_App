{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce91e042",
   "metadata": {},
   "source": [
    "### <b>문제 4-1 : OpenAI에서 Ollama Qwen3로 RAG 시스템 변경하기</b>\n",
    "<b>문제 설명</b><br>\n",
    ": 주어진 OpenAI 기반 RAG 시스템 코드를 로컬 Ollama Qwen3 모델을 사용하도록 변경하는 연습문제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e085e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "print(\"==> 1. 문서 로딩 → PDF 읽기...\")\n",
    "loader = PyPDFLoader('./data/tutorial-korean.pdf')\n",
    "documents = loader.load()\n",
    "print(f\"  총 {len(documents)}페이지 로드 완료\")\n",
    "\n",
    "print(\"==> 2. 문서 분할 → 작은 청크로 나누기\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # 청크 크기 (한국어 최적화)\n",
    "    chunk_overlap=200,      # 중복 부분 (맥락 보존)\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"] # 자연스러운 분할을 위한 구분자\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"  {len(chunks)}개 청크 생성 완료\")\n",
    "print(f\"  평균 청크 길이: {sum(len(chunk.page_content) for chunk in chunks) / len(chunks):.0f}자\")\n",
    "\n",
    "print(\"==> 3. 벡터화 → 임베딩으로 변환\")\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",  # 고성능 임베딩 모델\n",
    "    dimensions=1536\n",
    ")\n",
    "\n",
    "print(\"==> 4. 저장 → FAISS 벡터스토어에 저장\")\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "print(f\" FAISS 벡터스토어 생성 완료 ({len(chunks)}개 벡터)\")\n",
    "\n",
    "print(\"===> 5. 검색 → 질문과 유사한 문서 찾기\")\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 6}  # 상위 6개 관련 문서 검색\n",
    ")\n",
    "print(\" Retriever 설정 완료\")\n",
    "\n",
    "print(\"===> 6. 생성 → LLM으로 답변 생성\")\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1500\n",
    ")\n",
    "\n",
    "# 한국어 최적화 프롬프트\n",
    "prompt_template = \"\"\"\n",
    "당신은 BlueJ 프로그래밍 환경 전문가입니다. \n",
    "아래 문서 내용을 바탕으로 정확하고 친절한 답변을 제공해주세요.\n",
    "\n",
    "문서 내용:\n",
    "{retrieveDocuments}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변 규칙:\n",
    "1. 문서 내용만을 근거로 답변하세요\n",
    "2. 단계별 설명이 필요하면 순서대로 작성하세요  \n",
    "3. 구체적인 메뉴명, 버튼명을 포함하세요\n",
    "4. 문서에 없는 정보는 \"문서에서 찾을 수 없습니다\"라고 하세요\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "print(\" 프롬프트 설정 완료\")\n",
    "\n",
    "# ===================================\n",
    "# 7. QA 체인 생성\n",
    "# ===================================\n",
    "print(\"\\n ===> 7.  QA 체인 생성...\")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt, \"document_variable_name\": \"retrieveDocuments\"},\n",
    "    return_source_documents=True\n",
    ")\n",
    "print(\"  RAG 파이프라인 구축 완료!\")\n",
    "\n",
    "# ===================================\n",
    "# 8. 테스트 질문들\n",
    "# ===================================\n",
    "test_questions = [\n",
    "    \"BlueJ에서 객체를 생성하는 방법은 무엇인가요?\",\n",
    "    \"컴파일 오류가 발생했을 때 어떻게 확인할 수 있나요?\", \n",
    "    \"디버깅을 위해 중단점을 설정하는 방법을 알려주세요\",\n",
    "    \"코드패드는 무엇이고 어떻게 사용하나요?\",\n",
    "    \"애플릿을 만들고 실행하는 방법을 설명해주세요\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" RAG 시스템 테스트\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ===================================\n",
    "# 9. 질문 및 답변 실행\n",
    "# ===================================\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n【테스트 {i}/5】\")\n",
    "    print(f\" 질문: {question}\")\n",
    "    print(\" 답변 생성 중...\")\n",
    "    \n",
    "    # RAG 실행\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    answer = result[\"result\"]\n",
    "    source_docs = result[\"source_documents\"]\n",
    "    \n",
    "    print(f\"\\n 답변:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(answer)\n",
    "    \n",
    "    # 참조 문서 정보\n",
    "    print(f\"\\n 참조 문서:\")\n",
    "    for j, doc in enumerate(source_docs[:3], 1):\n",
    "        page = doc.metadata.get('page', 'N/A')\n",
    "        preview = doc.page_content[:80].replace('\\n', ' ')\n",
    "        print(f\"   {j}. 페이지 {page}: {preview}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 40)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
