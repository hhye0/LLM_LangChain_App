{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc745d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accf18d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Before (논리적이고 보수적인 이야기)\n",
      "어느 날, 마법의 세계에서 벌어지는 예상치 못한 사건이 발생했습니다. 마법사들은 모두 사라지고, 마법의 세계는 혼란에 빠졌습니다. 마법의 세계를 지키던 마법사들은 모두 어디로 사라졌을까요?\n",
      "\n",
      "마법의 세계를 탐험하던 한 소년은 마법사들이 사라진 이유를 찾기 위해 마법의 숲으로 향했습니다. 마법의 숲은 마법의 세계에서 가장 강력한 마법이 숨어 있는 곳으로 알려져 있었습니다.\n",
      "\n",
      "소년은 마법의 숲에서 마법사들이 사라진 흔적을 발견했습니다. 마법사들은 모두 마법의 숲 깊은 곳에 있는 비밀의 방으로 사라졌습니다. 소년\n",
      "\n",
      "-------------------------\n",
      "\n",
      " After (창의적인 이야기, 더 풍부한 표현)\n",
      "한밤중에 마법의 마을에서는 한 노인이 이고그램을 팔고 있었습니다. 이고그램은 마법의 세계에서 가장 강력한 마법 중 하나를 발휘하는 것으로 알려져 있었습니다. 이 노인은 이고그램을 마법의 물건으로 만들어 많은 돈을 벌었습니다.\n",
      "\n",
      "마을에서는 사람들의 이고그램에 대한 수요가 매우 높았지만, 이고그램의 효과는 점점 약해지고 있었습니다. 사람들은 이고그램의 효과를 믿지 않게 되었고, 이고그램의 가격은 하락했습니다.\n",
      "\n",
      "그런데, 이고그램의 효과가 약해진 것은 노인의 잘못이 아니었습니다. 이고그램의 효과는 이고그램의 원료인 '마법의 결정'이 부족했기 때문입니다. 노인은 이고그램을 계속 팔기 위해 마법의 결정을 찾으러 떠납니다.\n",
      "\n",
      "여행 도중, 노인은 이고그램을 파는 것이 자신의 잘못이었다는 것을 깨닫습니다. 이고그램은 마법의 세계에서 가장 강력한 마법 중 하나였지만, 이고그램의 효과는 사람들의 기대를 충족시키지 못했습니다. 노인은 이고그램을 파는 것을 멈추고, 마법의 결정을 찾으러 계속 여행을 합니다.\n",
      "\n",
      "노인은 이고그램을 파는 것을 멈추고, 마법의 결정을 찾으러 계속 여행을 합니다. 여행 도중, 노인은 이고그램의 효과를 약화시킨 것이 자신의 잘못이 아니\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#  보수적인 설정 (일관된, 논리적인 이야기)\n",
    "llm_before = ChatOpenAI(\n",
    "    #model=\"gpt-3.5-turbo-0125\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.2,  # 낮은 온도로 예측 가능한 출력\n",
    "    presence_penalty=0.0,  # 기존 패턴 유지\n",
    "    frequency_penalty=0.0,  # 반복 허용\n",
    "    max_tokens=150,  # 출력 길이 제한\n",
    "    top_p=1.0  # 확률 상위 100% 내에서 선택 (제한 없음)\n",
    ")\n",
    "\n",
    "#  창의적인 설정 (더 독창적이고 예측 불가능한 이야기)\n",
    "llm_after = ChatOpenAI(\n",
    "    #model=\"gpt-3.5-turbo-0125\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=1.2,  # 높은 온도로 창의적인 답변 유도\n",
    "    presence_penalty=1.2,  # 새로운 단어와 개념 유도\n",
    "    frequency_penalty=0.5,  # 반복을 억제하여 더 다양한 표현 생성\n",
    "    max_tokens=300,  # 더 긴 이야기 허용\n",
    "    top_p=0.8  # 제한 없이 다양한 단어 선택 가능\n",
    ")\n",
    "\n",
    "# 질문 설정: 짧은 판타지 이야기 생성\n",
    "# question = \"마법의 세계에서 용이 인간과 친구가 되는 짧은 이야기를 써 주세요.\"\n",
    "question = \"마법의 세계에서 벌어지는 예상치 못한 사건을 주제로 독창적인 짧은 이야기를 만들어 주세요.\"\n",
    "\n",
    "# 모델 호출\n",
    "response_before = llm_before.invoke(question)\n",
    "response_after = llm_after.invoke(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(\" Before (논리적이고 보수적인 이야기)\")\n",
    "print(response_before.content)\n",
    "\n",
    "print(\"\\n-------------------------\\n\")\n",
    "\n",
    "print(\" After (창의적인 이야기, 더 풍부한 표현)\")\n",
    "print(response_after.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55fa86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Before] 모델 결과\n",
      "### 추천 여행지: 서울 및 강화도\n",
      "\n",
      "*   **여행 기간:** 3박 4일\n",
      "*   **여행 일정:**\n",
      "\n",
      "**1일차: 서울**\n",
      "\n",
      "*   **아침: 출발 및 서울 도착**\n",
      "    *   서울에 도착하여 호텔에 체크인하고 간단한 아침 식사 후 휴식\n",
      "*   **오전: 경복궁**\n",
      "    *   경복궁으로 이동 (지하철 3호선) \n",
      "    *   경복궁 탐방 (약 2시간 소요)\n",
      "*   **오후: 서울 근교 나들이**\n",
      "    *   점심 식사 후, 종묘, 창덕궁, 그리고 북촌 한옥마을을 돌아보는 시간을 가질 수 있습니다. (약 2시간 소요)\n",
      "*   **저녁: 서울 근교 맛집 탐방**\n",
      "    *   저녁 식사는 서울 근교의 다양한 맛집에서 식사를 즐기세요.\n",
      "\n",
      "**2일차: 강화도**\n",
      "\n",
      "*   **아침: 강화도 이동**\n",
      "    *   아침 식사 후 강화도로 이동 (버스 또는 자가용으로 약 1시간 소요)\n",
      "*   **오전: 강화도 역사 유적지 탐방**\n",
      "    *   강화도 역사 유적지를 방문하여 강화도의 역사와 문화를 경험하세요. (약 2시간 소요)\n",
      "*   **오후: 강화도 자연 탐방**\n",
      "    *   점심 식\n",
      "\n",
      "================================================================================\n",
      "\n",
      " [After] 모델 결과\n",
      "### **여행지 추천: 서울 및 경기도**\n",
      "\n",
      "*   **여행일정: 3박 4일**\n",
      "*   **여행지: 서울 및 경기도**\n",
      "\n",
      "### **1일차: 서울**\n",
      "\n",
      "*   **아침: 서울역에서 출발**\n",
      "*   **오전: 경복궁** *   **주소:** 서울 종로구 사직로 161 *   **시간:** 9:00 - 18:00 (토, 일 18:30까지) *   **입장료:** 무료 (한복 착용 시 무료) *   **교통:** 지하철 3호선 경복궁역 5번 출구 *   **추천 메뉴:** *   **경복궁 근처:** *   **한정식:** *   **한옥마을 한정식:** 전통 한옥에서 즐기는 한정식 *   **궁중 한정식:** 경복궁 인근에서 전통 궁중 요리를 맛볼 수 있는 곳\n",
      "*   **오후: 북촌 한옥마을** *   **주소:** 서울 종로구 계동길 37 *   **시간:** 10:00 - 18:00 *   **입장료:** 무료 *   **교통:** 지하철 3호선 안국역 6번 출구 *   **추천 메뉴:** *   **북촌 한옥마을 근처:** *   **한옥 카페:** *   **북촌온:** 전통 한옥에서 즐기는 커피와 디저트 *   **온화담:** 한옥에서 즐기는 전통차와 디저트\n",
      "*   **저녁: 서울역 인근 식당** *   **추천 메뉴:** *   **서울역 인근:** *   **한우:** *   **한우 암소:** 서울역 인근에서 즐기는 한우 암소 *   **한우 명가:** 전통 한우 요리를 맛볼 수 있는 곳\n",
      "\n",
      "### **2일차: 경기도 수원**\n",
      "\n",
      "*   **아침: 수원역에서 출발**\n",
      "*   **오전: 수원 화성** *   **주소:** 경기도 수원시 팔달구 화성문길 1 *   **시간:** 9:00 - 18:00 (토, 일 18:30까지) *   **입장료:** 무료 (성곽 입장료 1,500원) *   **교통:** 지하철 1호선 수원역 1번 출구 *   **추천 메뉴:** *   **수원 화성 근처:** *   **수원 전통시장:** *   **수원 화성시장:** 전통시장에서 즐기는 수원 지역 특산물 *   **수원 팔달문시장:** 전통시장에서 즐기는 수원 지역 특산물\n",
      "*   **오후: 수원 광교호수공원** *   **주소:** 경기도 수원시 영통구 광교로 57 *   **시간:** 24시간 *   **입장료:** 무료 *   **교통:** 지하철 1호선 수원역 1번 출구 *   **추천 메뉴:** *   **수원 광교호수공원 근처:** *   **광교 카페거리:** *   **카페 더 시그넘 하우스:** 광교호수공원에서 즐기는 커피와 디저트 *   **카페 더 시그넘 하우스:** 광교호수공원에서 즐기는 커피와 디저트\n",
      "*   **저녁: 수원역 인근 식당** *   **추천 메뉴:** *   **수원역 인근:** *   **수원 지역 특산물:** *   **수원 왕갈비:** 수원 지역 특산물인 왕갈비를 맛볼 수 있는 곳 *   **수원 막걸리:** 전통 막걸리를 맛볼 수 있는 곳\n",
      "\n",
      "### **3일차: 경기도 용인**\n",
      "\n",
      "*   **아침: 용인역에서 출발**\n",
      "*   **오전: 에버랜드** *\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "#  모델 파라미터 (Before: 기본적인 추천 / After: 맞춤형 세부 정보 추가)\n",
    "before_params = {\n",
    "    \"temperature\": 0.7,         # 랜덤성을 적절히 유지 (다양한 답변 유도)\n",
    "    \"max_tokens\": 300,          # 응답 길이를 적절히 조절\n",
    "    \"frequency_penalty\": 0.5,   # 반복 단어 억제\n",
    "    \"presence_penalty\": 0.5,    # 새로운 단어 포함 장려\n",
    "}\n",
    "\n",
    "after_params = {\n",
    "    \"temperature\": 0.3,         # 창의성을 낮추고 정확한 답변 유도\n",
    "    \"max_tokens\": 800,          # 더 긴 답변을 생성 (세부 정보 포함)\n",
    "    \"top_p\": 0.85,              # 확률 기반 샘플링 (일관성과 다양성 균형)\n",
    "    \"frequency_penalty\": 0.2,   # 반복 단어 감소 (자연스러운 답변)\n",
    "    \"presence_penalty\": 0.3,    # 새로운 정보 포함 장려\n",
    "}\n",
    "\n",
    "#  두 개의 모델 생성 (Before / After)\n",
    "#before_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **before_params)\n",
    "before_model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    **before_params\n",
    ")\n",
    "#after_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **after_params)\n",
    "after_model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    **after_params\n",
    ")\n",
    "\n",
    "#  프롬프트 구성 (올바른 ChatMessagePromptTemplate 사용)\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"당신은 여행 전문가입니다. 사용자의 요청에 맞는 최적의 여행지를 추천해 주세요.\"\n",
    ")\n",
    "\n",
    "user_message = HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message, user_message])\n",
    "\n",
    "#  체인 생성 (Before / After)\n",
    "before_chain = chat_prompt | before_model\n",
    "after_chain = chat_prompt | after_model\n",
    "\n",
    "#  질문 설정 (Before / After의 차이점을 비교할 수 있도록 변경)\n",
    "test_question = \"가족과 함께 3박 4일 동안 한국에서 여유롭게 여행할 수 있는 일정을 동선을 고려하여 자세하게 추천해 주세요.\"\n",
    "\n",
    "#  Before 모델 실행\n",
    "before_response = before_chain.invoke({\"user_input\": test_question})\n",
    "\n",
    "#  After 모델 실행\n",
    "after_response = after_chain.invoke({\"user_input\": test_question})\n",
    "\n",
    "#  결과 출력\n",
    "print(\" [Before] 모델 결과\")\n",
    "print(before_response.content)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")  # 가독성을 위한 구분선\n",
    "print(\" [After] 모델 결과\")\n",
    "print(after_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb6b2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Before] 기본 max_tokens=150 (기본 답변)\n",
      "과거로 여행을 가고 싶다면 고대 이집트 시대로 가고 싶습니다. 그 이유는 고대 이집트에는 피라미드라는 세계적으로 유명한 건축물이 있다는 겁니다. 이 건축물은 현대 건축 기술로도 도전을 많이 받았지만 여전히 비밀에 싸여 있습니다. 이 건축물의 비밀을 직접 확인하고 싶습니다. 또한, 고대 이집트에는 신화와 전설이 풍부합니다. 신과 동물, 그리고 마법이 가득한 신화와 전설의 세계를 경험하고 싶습니다. 마지막으로, 고대 이집트는 의학과 천문학에서도 상당한 발전을 이룬 문명입니다. 제가 의학과 천문학에 대해서 배워보고 싶습니다.\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      " [After] max_tokens=150, stop=['.'] (첫 번째 마침표에서 응답 중단)\n",
      "시간 여행이 가능하다면, 과거의 어느 시대로 가고 싶은지와 그 이유를 창의적으로 설명해 드리겠습니다\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      " [After] max_tokens=150, temperature=0.8 (창의적인 답변)\n",
      "저는 시간여행이 가능하다면 고대 그리스로 가고 싶습니다.\n",
      "\n",
      "고대 그리스는 철학과 과학, 예술, 건축 등 다양한 분야에서 현대 문명의 근간이 되는 업적을 남긴 시대입니다. \n",
      "\n",
      "저는 고대 그리스로 여행을 가고 싶습니다. 고대 그리스의 유명한 철학자인 소크라테스, 플라톤, 아리스토텔레스와 같은 인물들을 만나 그들의 생각을 직접 듣고 싶습니다.\n",
      "\n",
      "또한 올림픽의 기원인 고대 올림픽을 직접 보고 싶습니다. 올림픽의 역사를 배우고, 고대 그리스의 문화와 스포츠 정신을 경험하고 싶습니다.\n",
      "\n",
      "고대 그리스의 신화와 전설에 나오는 신들과 여신들을 만나보고\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "#  프롬프트 설정 (천문학 질문에 대한 답변을 생성하는 시스템)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"이 시스템은 천문학 질문에 대해 명확하고 자세한 답변을 제공할 수 있습니다.\"),\n",
    "    (\"user\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "#  기본 모델 설정 (기본적인 답변 생성)\n",
    "#base_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", max_tokens=150)  # 150 토큰 제한\n",
    "base_model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "#  질문 설정\n",
    "# 1. MAX_TOKENS 차이를 보여주는 질문 (길이 제한 효과)\n",
    "max_tokens_question = \"인공지능의 발전이 미래 사회에 미칠 영향을 긍정적 측면과 부정적 측면으로 나누어 자세히 설명해 주세요.\"\n",
    "\n",
    "# 2. STOP 파라미터 차이를 보여주는 질문 (중단점 효과)\n",
    "stop_question = \"Python 프로그래밍을 배우는 초보자에게 추천하는 학습 단계를 순서대로 설명해 주세요. 각 단계별로 구체적인 방법과 팁을 포함해서 답변해 주세요.\"\n",
    "\n",
    "# 3. TEMPERATURE 차이를 보여주는 질문 (창의성 vs 정확성)\n",
    "temperature_question = \"시간 여행이 가능하다면 과거의 어느 시대로 가고 싶은지와 그 이유를 창의적으로 설명해 주세요.\"\n",
    "\n",
    "# 4. 복합적 비교를 위한 질문 (모든 파라미터 효과)\n",
    "complex_question = \"화성에 인류가 정착하기 위해 필요한 기술과 준비사항들을 단계별로 설명하고, 각 단계에서 예상되는 도전과제와 해결방안을 제시해 주세요.\"\n",
    "\n",
    "\n",
    "question = temperature_question\n",
    "\n",
    "#  Before (기본 max_tokens=150)\n",
    "messages = prompt.format_messages(user_input=question)\n",
    "before_answer = base_model.invoke(messages)\n",
    "\n",
    "#  Before 출력\n",
    "print(\"\\n [Before] 기본 max_tokens=150 (기본 답변)\")\n",
    "print(before_answer.content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")  # 가독성을 위한 구분선\n",
    "\n",
    "#  After (파라미터 조정 후 비교)\n",
    "stop_chain = prompt | base_model.bind(max_tokens=150, stop=[\".\"])  # 첫 번째 마침표에서 중단\n",
    "temp_chain = prompt | base_model.bind(max_tokens=150, temperature=0.8)  # 창의적인 답변 유도\n",
    "\n",
    "stop_answer = stop_chain.invoke({\"user_input\": question})\n",
    "temp_answer = temp_chain.invoke({\"user_input\": question})\n",
    "\n",
    "#  After 출력 (stop vs temperature 비교)\n",
    "print(\" [After] max_tokens=150, stop=['.'] (첫 번째 마침표에서 응답 중단)\")\n",
    "print(stop_answer.content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")  # 가독성을 위한 구분선\n",
    "\n",
    "print(\" [After] max_tokens=150, temperature=0.8 (창의적인 답변)\")\n",
    "print(temp_answer.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
